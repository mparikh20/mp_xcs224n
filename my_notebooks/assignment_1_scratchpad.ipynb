{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc4a565a",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcebfb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "053e3b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "157b9a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0907caab",
   "metadata": {},
   "outputs": [],
   "source": [
    "stanford_dir = cwd.parent / 'XCS224N-A1-master' / 'src'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0875596b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(str(stanford_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a0515be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to /Users/mukti/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefbf0fe",
   "metadata": {},
   "source": [
    "# Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c7a0a0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distinct_words(corpus):\n",
    "    \"\"\" Determine a list of distinct words for the corpus.\n",
    "        Params:\n",
    "            corpus (list of list of strings): corpus of documents\n",
    "        Return:\n",
    "()            corpus_words (list of strings): list of distinct words across the corpus, sorted (using python 'sorted' function)\n",
    "            num_corpus_words (integer): number of distinct words across the corpus\n",
    "    \"\"\"\n",
    "    corpus_words = []\n",
    "    num_corpus_words = 0\n",
    "\n",
    "    # ### START CODE HERE ###\n",
    "    corpus_words = sorted(list({item for document in corpus for item in document if item.isalpha() or item in ['<START>','<END>']}))\n",
    "    num_corpus_words = len(corpus_words)\n",
    "    # ### END CODE HERE ###\n",
    "\n",
    "    return corpus_words, num_corpus_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a21b5236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "c1 = '<START> all that glitters is not gold . <END>'\n",
    "c2 = '<START> all is well that ends well . <END>'\n",
    "\n",
    "corpus = [c1.split(), c2.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "524785f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<START>', 'all', 'that', 'glitters', 'is', 'not', 'gold', '.', '<END>'],\n",
       " ['<START>', 'all', 'is', 'well', 'that', 'ends', 'well', '.', '<END>']]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "5397311a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_words, num_corpus_words = distinct_words(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5141f991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<END>',\n",
       " '<START>',\n",
       " 'all',\n",
       " 'ends',\n",
       " 'glitters',\n",
       " 'gold',\n",
       " 'is',\n",
       " 'not',\n",
       " 'that',\n",
       " 'well']"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "77f8492b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_corpus_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7195d80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reuters_corpus = read_corpus()[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c9c50a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<START>',\n",
       " 'texaco',\n",
       " '&',\n",
       " 'lt',\n",
       " ';',\n",
       " 'txc',\n",
       " '>',\n",
       " 'canada',\n",
       " 'to',\n",
       " 'raise',\n",
       " 'crude',\n",
       " 'oil',\n",
       " 'postings',\n",
       " 'texaco',\n",
       " 'inc',\n",
       " \"'\",\n",
       " 's',\n",
       " 'texaco',\n",
       " 'canada',\n",
       " 'said',\n",
       " 'it',\n",
       " 'will',\n",
       " 'raise',\n",
       " 'postings',\n",
       " 'for',\n",
       " 'its',\n",
       " 'edmonton',\n",
       " '/',\n",
       " 'swann',\n",
       " 'hills',\n",
       " 'crude',\n",
       " 'by',\n",
       " '24',\n",
       " 'canadian',\n",
       " 'cts',\n",
       " 'a',\n",
       " 'barrel',\n",
       " ',',\n",
       " 'effective',\n",
       " 'june',\n",
       " '20',\n",
       " '.',\n",
       " 'the',\n",
       " 'company',\n",
       " 'said',\n",
       " 'the',\n",
       " 'new',\n",
       " 'posting',\n",
       " 'for',\n",
       " 'edmonton',\n",
       " '/',\n",
       " 'swann',\n",
       " 'hills',\n",
       " 'will',\n",
       " 'be',\n",
       " '25',\n",
       " '.',\n",
       " '60',\n",
       " 'dlrs',\n",
       " 'a',\n",
       " 'barrel',\n",
       " '.',\n",
       " 'the',\n",
       " 'price',\n",
       " 'hike',\n",
       " 'follows',\n",
       " 'a',\n",
       " 'round',\n",
       " 'of',\n",
       " 'crude',\n",
       " 'oil',\n",
       " 'price',\n",
       " 'increases',\n",
       " 'started',\n",
       " 'late',\n",
       " 'june',\n",
       " '17',\n",
       " 'by',\n",
       " 'sun',\n",
       " 'co',\n",
       " '.',\n",
       " 'the',\n",
       " 'other',\n",
       " 'major',\n",
       " 'canadian',\n",
       " 'crude',\n",
       " 'suppliers',\n",
       " 'raised',\n",
       " 'prices',\n",
       " 'june',\n",
       " '18',\n",
       " '.',\n",
       " '<END>']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reuters_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "752c546d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_co_occurrence_matrix(corpus, window_size=4):\n",
    "    \"\"\" Compute co-occurrence matrix for the given corpus and window_size (default of 4).\n",
    "\n",
    "        Note: Each word in a document should be at the center of a window. Words near edges will have a smaller\n",
    "              number of co-occurring words.\n",
    "\n",
    "              For example, if we take the document \"START All that glitters is not gold END\" with window size of 4,\n",
    "              \"All\" will co-occur with \"START\", \"that\", \"glitters\", \"is\", and \"not\".\n",
    "\n",
    "        Params:\n",
    "            corpus (list of list of strings): corpus of documents\n",
    "            window_size (int): size of context window\n",
    "        Return:\n",
    "            M (numpy matrix of shape (number of unique words in the corpus , number of unique words in the corpus)):\n",
    "                Co-occurrence matrix of word counts.\n",
    "                The ordering of the words in the rows/columns should be the same as the ordering of the words given by the distinct_words function.\n",
    "            word2Ind (dict): dictionary that maps word to index (i.e. row/column number) for matrix M.\n",
    "    \"\"\"\n",
    "    words, num_words = distinct_words(corpus)\n",
    "    M = None\n",
    "    word2Ind = {}\n",
    "\n",
    "    # ### START CODE HERE ###\n",
    "    # initialize a matrix of size num_words\n",
    "    M = np.zeros((num_words,num_words))\n",
    "    \n",
    "    # create a dictionary that takes the sorted words list and then assigns an index to each\n",
    "    # This dict will help in mapping the word pairs to add values in the M matrix\n",
    "    word2Ind = dict((word,n) for n, word in enumerate(words))\n",
    "    \n",
    "    # create a clean corpus structure that eliminates characters but keeps the list of lists\n",
    "    cleaned_corpus = [[item for item in document if item.isalpha() or item in ['<START>','<END>']] for document in corpus]\n",
    "    \n",
    "    # cleaned_corpus is a list of lists. Each list is a document.\n",
    "    # Each list has strings\n",
    "    for document in cleaned_corpus:\n",
    "        # loop over each word that would be a center word\n",
    "        for center_i in range(len(document)):\n",
    "            # this will only select indices that span the window around the center word and within range\n",
    "            # context_m is the index of a word present around the center word in a window of size window_size\n",
    "            for context_m in filter(lambda x: 0 <= x <= len(document)-1, \n",
    "                                map(lambda x: x + center_i, range(-window_size,window_size+1))):\n",
    "                \n",
    "                # get the center word and context word\n",
    "                center_word = document[center_i]\n",
    "                context_word = document[context_m]\n",
    "                \n",
    "                # access these words from the dictionary\n",
    "                # Allot the row index of M to be for center words and column index for the context word\n",
    "                if center_word in word2Ind and context_word in word2Ind:\n",
    "                    M[word2Ind[center_word],word2Ind[context_word]] += 1\n",
    "                    \n",
    "    # ### END CODE HERE ###\n",
    "\n",
    "    return M, word2Ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1299bff5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58ebb86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8acee6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300c4e1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0eeb532d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-2, -1, 0, 1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x: x + 2 ,range(-4,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4c93d9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2\n",
      "-1\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "for n in map(lambda x: x + 2 ,range(-4,5)):\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "02a0e3c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<END>': 0,\n",
       " '<START>': 1,\n",
       " 'all': 2,\n",
       " 'ends': 3,\n",
       " 'glitters': 4,\n",
       " 'gold': 5,\n",
       " 'is': 6,\n",
       " 'not': 7,\n",
       " 'that': 8,\n",
       " 'well': 9}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2Ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "cc79f317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<START>', 'all', 'that', 'glitters', 'is', 'not', 'gold', '<END>'],\n",
       " ['<START>', 'all', 'is', 'well', 'that', 'ends', 'well', '<END>']]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "adc1a71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "85bb052f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0eaea79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = {'cest':0,\n",
    "             'un': 1,\n",
    "             'dimanche':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b2445cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[test_dict['cest'],test_dict['un']] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "948cd91c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843f2b38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
